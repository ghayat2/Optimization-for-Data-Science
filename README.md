# Optimization-for-Data-Science - ETH ZÃ¼rich

This course discussed classic first and second order methods such as gradient descent and Newton's method can be adapted to scale to large datasets, in theory and in practice. It also covers some new algorithms and paradigms that have been developed specifically in the context of data science. In addition, it discusses convex programming relaxations as a powerful and versatile paradigm for designing efficient algorithms to solve computational problems arising in data science. 
